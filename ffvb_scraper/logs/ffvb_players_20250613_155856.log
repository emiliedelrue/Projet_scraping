2025-06-13 15:58:56 [scrapy.utils.log] INFO: Scrapy 2.13.2 started (bot: ffvb_scraper)
2025-06-13 15:58:56 [scrapy.utils.log] INFO: Versions:
{'lxml': '5.4.0',
 'libxml2': '2.11.9',
 'cssselect': '1.3.0',
 'parsel': '1.10.0',
 'w3lib': '2.3.1',
 'Twisted': '25.5.0',
 'Python': '3.13.3 (tags/v3.13.3:6280bb5, Apr  8 2025, 14:47:33) [MSC v.1943 '
           '64 bit (AMD64)]',
 'pyOpenSSL': '25.1.0 (OpenSSL 3.5.0 8 Apr 2025)',
 'cryptography': '45.0.4',
 'Platform': 'Windows-11-10.0.26100-SP0'}
2025-06-13 15:58:56 [scrapy.addons] INFO: Enabled addons:
[]
2025-06-13 15:58:56 [py.warnings] WARNING: C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\utils\request.py:120: ScrapyDeprecationWarning: 'REQUEST_FINGERPRINTER_IMPLEMENTATION' is a deprecated setting.
It will be removed in a future version of Scrapy.
  return cls(crawler)

2025-06-13 15:58:56 [asyncio] DEBUG: Using selector: SelectSelector
2025-06-13 15:58:56 [scrapy.utils.log] DEBUG: Using reactor: twisted.internet.asyncioreactor.AsyncioSelectorReactor
2025-06-13 15:58:56 [scrapy.utils.log] DEBUG: Using asyncio event loop: asyncio.windows_events._WindowsSelectorEventLoop
2025-06-13 15:58:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.feedexport.FeedExporter',
 'scrapy.extensions.logstats.LogStats',
 'scrapy.extensions.throttle.AutoThrottle',
 'scrapy.extensions.corestats.CoreStats']
2025-06-13 15:58:56 [scrapy.crawler] INFO: Overridden settings:
{'AUTOTHROTTLE_DEBUG': True,
 'AUTOTHROTTLE_ENABLED': True,
 'AUTOTHROTTLE_MAX_DELAY': 10,
 'AUTOTHROTTLE_START_DELAY': 1,
 'BOT_NAME': 'ffvb_scraper',
 'CONCURRENT_REQUESTS': 1,
 'CONCURRENT_REQUESTS_PER_DOMAIN': 1,
 'DOWNLOAD_DELAY': 1,
 'DOWNLOAD_TIMEOUT': 30,
 'FEED_EXPORT_ENCODING': 'utf-8',
 'HTTPCACHE_ENABLED': True,
 'LOG_FILE': 'logs/ffvb_players_20250613_155856.log',
 'MEMUSAGE_LIMIT_MB': 2048,
 'MEMUSAGE_WARNING_MB': 1024,
 'NEWSPIDER_MODULE': 'ffvb_scraper.spiders',
 'RANDOMIZE_DOWNLOAD_DELAY': 0.2,
 'REDIRECT_MAX_TIMES': 5,
 'REQUEST_FINGERPRINTER_IMPLEMENTATION': '2.7',
 'RETRY_HTTP_CODES': [500, 502, 503, 504, 408, 429, 400, 403],
 'RETRY_TIMES': 3,
 'ROBOTSTXT_OBEY': True,
 'SPIDER_MODULES': ['ffvb_scraper.spiders'],
 'USER_AGENT': 'ffvb_scraper (+http://educational-purpose.local)'}
2025-06-13 15:59:00 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.downloadermiddlewares.robotstxt.RobotsTxtMiddleware',
 'scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'ffvb_scraper.middlewares.RotateUserAgentMiddleware',
 'ffvb_scraper.middlewares.HeadersMiddleware',
 'ffvb_scraper.middlewares.CustomRetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'ffvb_scraper.middlewares.ThrottleMiddleware',
 'ffvb_scraper.middlewares.LoggingMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'ffvb_scraper.middlewares.ResponseSizeMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'ffvb_scraper.middlewares.ErrorHandlingMiddleware',
 'ffvb_scraper.middlewares.CacheMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats',
 'scrapy.downloadermiddlewares.httpcache.HttpCacheMiddleware']
2025-06-13 15:59:00 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.start.StartSpiderMiddleware',
 'scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'ffvb_scraper.middlewares.FFVBScraperSpiderMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2025-06-13 15:59:00 [py.warnings] WARNING: C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\core\spidermw.py:98: ScrapyDeprecationWarning: The following enabled spider middlewares, directly or through their parent classes, define the deprecated process_start_requests() method: ffvb_scraper.middlewares.FFVBScraperSpiderMiddleware. process_start_requests() has been deprecated in favor of a new method, process_start(), to support asynchronous code execution. process_start_requests() will stop being called in a future version of Scrapy. If you use Scrapy 2.13 or higher only, replace process_start_requests() with process_start(); note that process_start() is a coroutine (async def). If you need to maintain compatibility with lower Scrapy versions, when defining process_start_requests() in a spider middleware class, define process_start() as well. See the release notes of Scrapy 2.13 for details: https://docs.scrapy.org/en/2.13/news.html
  warn(

2025-06-13 15:59:00 [scrapy.core.spidermw] WARNING: Middleware ffvb_scraper.middlewares.FFVBScraperSpiderMiddleware doesn't support asynchronous spider output, this is deprecated and will stop working in a future version of Scrapy. The middleware should be updated to support it. Please see https://docs.scrapy.org/en/latest/topics/coroutines.html#for-middleware-users for more information.
2025-06-13 15:59:00 [twisted] CRITICAL: Unhandled error in Deferred:
2025-06-13 15:59:01 [twisted] CRITICAL: 
Traceback (most recent call last):
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\twisted\internet\defer.py", line 1857, in _inlineCallbacks
    result = context.run(gen.send, result)
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\crawler.py", line 156, in crawl
    self.engine = self._create_engine()
                  ~~~~~~~~~~~~~~~~~~~^^
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\crawler.py", line 169, in _create_engine
    return ExecutionEngine(self, lambda _: self.stop())
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\core\engine.py", line 111, in __init__
    self.scraper: Scraper = Scraper(crawler)
                            ~~~~~~~^^^^^^^^^
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\core\scraper.py", line 107, in __init__
    self.itemproc: ItemPipelineManager = itemproc_cls.from_crawler(crawler)
                                         ~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\middleware.py", line 77, in from_crawler
    return cls._from_settings(crawler.settings, crawler)
           ~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\middleware.py", line 86, in _from_settings
    mwcls = load_object(clspath)
  File "C:\Users\Eva DEPAEPE\AppData\Local\Packages\PythonSoftwareFoundation.Python.3.13_qbz5n2kfra8p0\LocalCache\local-packages\Python313\site-packages\scrapy\utils\misc.py", line 71, in load_object
    mod = import_module(module)
  File "C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.13_3.13.1008.0_x64__qbz5n2kfra8p0\Lib\importlib\__init__.py", line 88, in import_module
    return _bootstrap._gcd_import(name[level:], package, level)
           ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "<frozen importlib._bootstrap>", line 1387, in _gcd_import
  File "<frozen importlib._bootstrap>", line 1360, in _find_and_load
  File "<frozen importlib._bootstrap>", line 1331, in _find_and_load_unlocked
  File "<frozen importlib._bootstrap>", line 935, in _load_unlocked
  File "<frozen importlib._bootstrap_external>", line 1022, in exec_module
  File "<frozen importlib._bootstrap_external>", line 1160, in get_code
  File "<frozen importlib._bootstrap_external>", line 1090, in source_to_code
  File "<frozen importlib._bootstrap>", line 488, in _call_with_frames_removed
  File "C:\Users\Eva DEPAEPE\OneDrive - SEENOVATE\Documents\Mastere\web_scraping\ffvb_scraper\ffvb_scraper\pipelines.py", line 187
    elif adapter
                ^
SyntaxError: expected ':'
